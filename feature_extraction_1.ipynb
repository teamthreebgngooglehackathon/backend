{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.path)\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"results/user_preprocessing/survey_results_public.csv\")\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "n_row=df.shape[0]\n",
    "print(df.isnull().sum()/n_row)\n",
    "attr_to_drop=[]\n",
    "attr_to_drop.append(\"SurveyTooLong\")\n",
    "attr_to_drop.append('SurveyEasy')\n",
    "attr_to_drop.append(\"AdBlocker\")\n",
    "attr_to_drop.append(\"AdBlockerDisable\")\n",
    "attr_to_drop.append(\"AdBlockerReasons\")\n",
    "attr_to_drop.append(\"AdsAgreeDisagree1\")\n",
    "attr_to_drop.append(\"AdsAgreeDisagree2\")\n",
    "attr_to_drop.append(\"AdsAgreeDisagree3\")\n",
    "attr_to_drop.append(\"AdsActions\")\n",
    "attr_to_drop.append(\"AdsPriorities1\")\n",
    "attr_to_drop.append(\"AdsPriorities2\")\n",
    "attr_to_drop.append(\"AdsPriorities3\")\n",
    "attr_to_drop.append(\"AdsPriorities4\")\n",
    "attr_to_drop.append(\"AdsPriorities5\")\n",
    "attr_to_drop.append(\"AdsPriorities6\")\n",
    "attr_to_drop.append(\"AdsPriorities7\")\n",
    "attr_to_drop.append(\"AIDangerous\")\n",
    "attr_to_drop.append(\"AIInteresting\")\n",
    "attr_to_drop.append(\"AIResponsible\")\n",
    "attr_to_drop.append(\"AIFuture\")\n",
    "attr_to_drop.append(\"EthicsChoice\")\n",
    "attr_to_drop.append(\"EthicsReport\")\n",
    "attr_to_drop.append(\"EthicsResponsible\")\n",
    "attr_to_drop.append(\"EthicsImplications\")\n",
    "attr_to_drop.append(\"EthicsChoice\")\n",
    "attr_to_drop.append(\"StackOverflowRecommend\")\n",
    "attr_to_drop.append(\"StackOverflowVisit\")\n",
    "attr_to_drop.append(\"StackOverflowHasAccount\")\n",
    "attr_to_drop.append(\"StackOverflowParticipate\")\n",
    "attr_to_drop.append(\"StackOverflowJobs\")\n",
    "attr_to_drop.append(\"StackOverflowDevStory\")\n",
    "attr_to_drop.append(\"StackOverflowJobsRecommend\")\n",
    "attr_to_drop.append(\"StackOverflowConsiderMember\")\n",
    "attr_to_drop.append(\"HypotheticalTools1\")\n",
    "attr_to_drop.append(\"HypotheticalTools2\")\n",
    "attr_to_drop.append(\"HypotheticalTools3\")\n",
    "attr_to_drop.append(\"HypotheticalTools4\")\n",
    "attr_to_drop.append(\"HypotheticalTools5\")\n",
    "attr_to_drop.append(\"JobContactPriorities1\")\n",
    "attr_to_drop.append(\"JobContactPriorities2\")\n",
    "attr_to_drop.append(\"JobContactPriorities3\")\n",
    "attr_to_drop.append(\"JobContactPriorities4\")\n",
    "attr_to_drop.append(\"JobContactPriorities5\")\n",
    "attr_to_drop.append(\"TimeAfterBootcamp\")\n",
    "df=df.drop(df.columns[[126,3,8,15,50,51,53,62,63,64,123,125,43,44,45,46,47,48,49]],axis=1)\n",
    "print(df.columns)\n",
    "df=df[df.columns.difference(attr_to_drop)]\n",
    "print(df.head())\n",
    "attr_to_drop=[\"HackathonReasons\",\"ErgonomicDevices\"]\n",
    "df=df[df.columns.difference(attr_to_drop)]\n",
    "\n",
    "\n",
    "print(sum(df.isnull().sum())/float(np.prod(df.shape)))\n",
    "col_null=df.isnull().sum()/n_row\n",
    "print(col_null.sort_values(ascending=False))\n",
    "#print(sum(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New set of attributes to be removed\n",
    "attr_to_drop=['Hobby','NumberMonitors','Salary','CheckInCode','WakeTime','TimeFullyProductive','SkipMeals','SexualOrientation','HoursOutside','Exercise','EthicalImplications','EducationParents']\n",
    "print(len(df.columns))\n",
    "df=df[df.columns.difference(attr_to_drop)]\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"removed2.csv\")\n",
    "import numpy as np\n",
    "df1 = df.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the unique values in each categorical attribute\n",
    "Frameworknextyear=list()\n",
    "for value in df1[\"FrameworkDesireNextYear\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            Frameworknextyear.append(i)\n",
    "sFNY=set(Frameworknextyear)\n",
    "FrameworkWorkedWith=list()\n",
    "for value in df1[\"FrameworkWorkedWith\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            FrameworkWorkedWith.append(i)\n",
    "sFW=set(FrameworkWorkedWith)\n",
    "PlatformDesireNextYear=list()\n",
    "for value in df1[\"PlatformDesireNextYear\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            PlatformDesireNextYear.append(i)\n",
    "sPDNY=set(PlatformDesireNextYear)\n",
    "PlatformWorkedWith=list()\n",
    "for value in df1[\"PlatformWorkedWith\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            PlatformWorkedWith.append(i)\n",
    "sPWW=set(PlatformWorkedWith)\n",
    "LanguageDesireNextYear=list()\n",
    "for value in df1[\"LanguageDesireNextYear\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            LanguageDesireNextYear.append(i)\n",
    "sLDNY=set(LanguageDesireNextYear)\n",
    "LanguageWorkedWith=list()\n",
    "for value in df1[\"LanguageWorkedWith\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            LanguageWorkedWith.append(i)\n",
    "sLWW=set(LanguageWorkedWith)\n",
    "         \n",
    "CommunicationTools=list()\n",
    "for value in df1[\"CommunicationTools\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            CommunicationTools.append(i)\n",
    "sCT=set(CommunicationTools)\n",
    "\n",
    "DatabaseWorkedWith=list()\n",
    "for value in df1[\"DatabaseWorkedWith\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            DatabaseWorkedWith.append(i)\n",
    "sDWW=set(DatabaseWorkedWith)\n",
    "\n",
    "DatabaseDesireNextYear=list()\n",
    "for value in df1[\"DatabaseDesireNextYear\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            DatabaseDesireNextYear.append(i)\n",
    "sDNY=set(DatabaseDesireNextYear)\n",
    "\n",
    "DevType=list()\n",
    "for value in df1[\"DevType\"]:\n",
    "        new=value.split(';')\n",
    "        for i in new:\n",
    "            DevType.append(i)\n",
    "sDT=set(DevType)\n",
    "sFNY.remove(\"\")\n",
    "sFW.remove(\"\")\n",
    "sPDNY.remove(\"\")\n",
    "sPWW.remove(\"\")\n",
    "sLDNY.remove(\"\")\n",
    "sLWW.remove(\"\")\n",
    "sCT.remove(\"\")\n",
    "sDWW.remove(\"\")\n",
    "sDNY.remove(\"\")\n",
    "sDT.remove(\"\")\n",
    "print(sFNY)\n",
    "print(sFW)\n",
    "print(sPDNY)\n",
    "print(sPWW)\n",
    "print(sLDNY)\n",
    "print(sLWW)\n",
    "print(sCT)\n",
    "print(sDWW)\n",
    "print(sDNY)\n",
    "print(sDT)\n",
    "combined=sFNY.union(sFW,sFNY,sPDNY,sPWW,sLDNY,sLWW,sCT,sDWW,sDNY,sDT)\n",
    "print(type(combined))\n",
    "all_framework=list(combined)\n",
    "print(all_framework)\n",
    "all_fw=pd.DataFrame(all_framework)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fw.head()\n",
    "print(all_fw.columns)\n",
    "#all_fw.to_csv(\"allFrameworks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted categorical variables into numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "print(set(df1['JobSatisfaction']))\n",
    "number=LabelEncoder()\n",
    "df1['CareerSatisfaction']=number.fit_transform(df1['CareerSatisfaction'])\n",
    "df1['Employment']=number.fit_transform(df1['Employment'])\n",
    "df1['FormalEducation']=number.fit_transform(df1['FormalEducation'])\n",
    "df1['Gender']=number.fit_transform(df1['Gender'])\n",
    "df1['HopeFiveYears']=number.fit_transform(df1['HopeFiveYears'])\n",
    "df1['HoursComputer']=number.fit_transform(df1['HoursComputer'])\n",
    "df1['JobSatisfaction']=number.fit_transform(df1['JobSatisfaction'])\n",
    "df1['OpenSource']=number.fit_transform(df1['OpenSource'])\n",
    "df1['OperatingSystem']=number.fit_transform(df1['OperatingSystem'])\n",
    "df1['Student']=number.fit_transform(df1['Student'])\n",
    "df1['UndergradMajor']=number.fit_transform(df1['UndergradMajor'])\n",
    "df1['YearsCoding']=number.fit_transform(df1['YearsCoding'])\n",
    "df1['YearsCodingProf']=number.fit_transform(df1['YearsCodingProf'])\n",
    "\n",
    "#df1.to_csv(\"./data/user_preprocessing/categoricalconverted.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sFNY.add('Respondent')\n",
    "#Create a separate dataframe based on one hot encoding for the attributes.\n",
    "# Framework=pd.DataFrame(columns=sFNY)\n",
    "# idx=0\n",
    "# Framework.insert(loc=idx,column='Respondent', value=[0])\n",
    "# #print(Framework.columns)\n",
    "# print(Framework.shape[0])\n",
    "# coldic=dict(zip(Framework.columns,range(0,13)))\n",
    "# print(coldic)\n",
    "# #print(df1.columns)\n",
    "# print(df1.shape[0])\n",
    "# for i in range(3):\n",
    "#     Framework = Framework.append({}, ignore_index=True)\n",
    "FrameworkWorkedWith = pd.DataFrame(df1['Respondent'])\n",
    "for i in sFW:\n",
    "    \n",
    "    FrameworkWorkedWith[i]=\"\"\n",
    "PlatformWorkedWith = pd.DataFrame(df1['Respondent'])\n",
    "for i in sPWW:\n",
    "    print(i)\n",
    "    PlatformWorkedWith[i]=\"\"\n",
    "LanguageWorkedWith = pd.DataFrame(df1['Respondent'])\n",
    "for i in sLWW:\n",
    "    LanguageWorkedWith[i]=\"\"\n",
    "DatabaseWorkedWith = pd.DataFrame(df1['Respondent'])\n",
    "for i in sDWW:\n",
    "    DatabaseWorkedWith[i]=\"\"\n",
    "DevType = pd.DataFrame(df1['Respondent'])\n",
    "for i in sDT:\n",
    "    DevType[i]=\"\"\n",
    "CommunicationTools = pd.DataFrame(df1['Respondent'])\n",
    "for i in sCT:\n",
    "    CommunicationTools[i]=\"\"\n",
    "#framework.to_csv(\"framework.csv\")\n",
    "#framework.resize=[[98855,,len(sFNY)]]\n",
    "print(len(sFW))\n",
    "print(len(sPWW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Framework.shape[0])\n",
    "# Framework.to_csv(\"hello1.csv\")\n",
    "time_start=time.time()\n",
    "coldic=dict(zip(FrameworkWorkedWith.columns,range(0,len(sFW)+1)))\n",
    "print(coldic)\n",
    "print(df1.head())\n",
    "for i in range(98855):\n",
    "    data=(df1.loc[i,'FrameworkWorkedWith']).split(';')\n",
    "    if(data[0]!=\"\"):\n",
    "       # print(data)\n",
    "        for value in data:\n",
    "            FrameworkWorkedWith.iloc[i,coldic[value]]=1\n",
    "time_end=time.time()\n",
    "print(time_end-time_start)\n",
    "#PlatformWorkedWith\n",
    "coldic1=dict(zip(PlatformWorkedWith.columns,range(0,len(sPWW)+1)))\n",
    "print(coldic1)\n",
    "#print(df1.head())\n",
    "for i in range(98855):\n",
    "    data=(df1.loc[i,'PlatformWorkedWith']).split(';')\n",
    "    if(data[0]!=\"\"):\n",
    "       # print(data)\n",
    "        for value in data:\n",
    "            PlatformWorkedWith.iloc[i,coldic1[value]]=1\n",
    "#LanguageWorkedWith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FrameworkWorkedWith.head())\n",
    "print(PlatformWorkedWith.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_LWW=time.time()\n",
    "coldic2=dict(zip(LanguageWorkedWith.columns,range(0,len(sLWW)+1)))\n",
    "print(coldic2)\n",
    "print(df1.head())\n",
    "for i in range(98855):\n",
    "    data=(df1.loc[i,'LanguageWorkedWith']).split(';')\n",
    "    if(data[0]!=\"\"):\n",
    "       # print(data)\n",
    "        for value in data:\n",
    "            LanguageWorkedWith.iloc[i,coldic2[value]]=1\n",
    "time_LWWe=time.time()\n",
    "print(\"Language\",time_LWWe-time_LWW)\n",
    "print(\"done\")\n",
    "#DatabasesWorkedWth\n",
    "time_DWW=time.time()\n",
    "coldic3=dict(zip(DatabaseWorkedWith.columns,range(0,len(sDWW)+1)))\n",
    "print(coldic3)\n",
    "print(df1.head())\n",
    "for i in range(98855):\n",
    "    data=(df1.loc[i,'DatabaseWorkedWith']).split(';')\n",
    "    if(data[0]!=\"\"):\n",
    "       # print(data)\n",
    "        for value in data:\n",
    "            DatabaseWorkedWith.iloc[i,coldic3[value]]=1\n",
    "time_DWWe=time.time()\n",
    "print(\"Databases\",time_DWWe-time_DWW)\n",
    "#DevType\n",
    "#print(\"done\")\n",
    "time_DT=time.time()\n",
    "coldic4=dict(zip(DevType.columns,range(0,len(sDT)+1)))\n",
    "print(coldic4)\n",
    "print(df1.head())\n",
    "for i in range(98855):\n",
    "    data=(df1.loc[i,'DevType']).split(';')\n",
    "    if(data[0]!=\"\"):\n",
    "       # print(data)\n",
    "        for value in data:\n",
    "            DevType.iloc[i,coldic4[value]]=1\n",
    "time_DTe=time.time()\n",
    "print(\"DevType\",time_DTe-time_DT)\n",
    "#CommmunicationTools\n",
    "coldic5=dict(zip(CommunicationTools.columns,range(0,len(sCT)+1)))\n",
    "print(coldic5)\n",
    "print(df1.head())\n",
    "for i in range(98855):\n",
    "    data=(df1.loc[i,'CommunicationTools']).split(';')\n",
    "    if(data[0]!=\"\"):\n",
    "       # print(data)\n",
    "        for value in data:\n",
    "            CommunicationTools.iloc[i,coldic5[value]]=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FrameworkWorkedWith.to_csv(\"./data/user_preprocessing/FrameworkWorkedWith.csv\")\n",
    "# PlatformWorkedWith.to_csv(\"./data/user_preprocessing/PlatformWorkedWith.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LanguageWorkedWith.to_csv(\"./data/user_preprocessing/LanguageWorkedWith.csv\")\n",
    "# DatabaseWorkedWith.to_csv(\"./data/user_preprocessing/DatabaseWorkedWith.csv\")\n",
    "# CommunicationTools.to_csv(\"./data/user_preprocessing/CommunicationTools.csv\")\n",
    "# DevType.to_csv(\"./data/user_preprocessing/DevType.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
