{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 28 by chrislovejoy\n",
    "Adapted by Regen Petu-Stiles\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def find_jobs_from(website, job_title, location, desired_characs, filename=\"results.csv\"):    \n",
    "    \"\"\"\n",
    "    This function extracts all the desired characteristics of all new job postings\n",
    "    of the title and location specified and returns them in single file.\n",
    "    The arguments it takes are:\n",
    "        - Website: to specify which website to search (options: 'careersinafrica' or 'CWjobs')\n",
    "        - Job_title\n",
    "        - Location\n",
    "        - Desired_characs: this is a list of the job characteristics of interest,\n",
    "            from titles, companies, links and date_listed.\n",
    "        - Filename: to specify the filename and format of the output.\n",
    "            Default is .csv file called 'results.csv'\n",
    "    \"\"\"\n",
    "    \n",
    "    if website == 'careersinafrica':\n",
    "        job_soup = load_indeed_jobs_div(job_title, location)\n",
    "        jobs_list, num_listings = extract_job_information_indeed(job_soup, desired_characs)\n",
    "    \n",
    "    if website == 'CWjobs':\n",
    "        location_of_driver = os.getcwd()\n",
    "        driver = initiate_driver(location_of_driver, browser='chrome')\n",
    "        job_soup = make_job_search(job_title, location, driver)\n",
    "        jobs_list, num_listings = extract_job_information_cwjobs(job_soup, desired_characs)\n",
    "    \n",
    "    save_jobs_to_excel(jobs_list, filename)\n",
    " \n",
    "    print('{} new job postings retrieved from {}. Stored in {}.'.format(num_listings, \n",
    "                                                                          website, filename))\n",
    "    \n",
    "\n",
    "## ======================= GENERIC FUNCTIONS ======================= ##\n",
    "\n",
    "def save_jobs_to_excel(jobs_list, filename):\n",
    "    jobs = pd.DataFrame(jobs_list)\n",
    "    jobs.to_excel(filename)\n",
    "\n",
    "\n",
    "\n",
    "## ================== FUNCTIONS FOR careersinafrica =================== ##\n",
    "\n",
    "def load_indeed_jobs_div(job_title, location):\n",
    "    getVars = {'q' : job_title, 'l' : location, 'fromage' : 'last', 'sort' : 'date'}\n",
    "    url = ('https://www.careersinafrica.com/job-search/' + urllib.parse.urlencode(getVars))\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    job_soup = soup.find(id=\"resultsCol\")\n",
    "    return job_soup\n",
    "\n",
    "def extract_job_information_indeed(job_soup, desired_characs):\n",
    "    job_elems = job_soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "     \n",
    "    cols = []\n",
    "    extracted_info = []\n",
    "    \n",
    "    \n",
    "    if 'titles' in desired_characs:\n",
    "        titles = []\n",
    "        cols.append('titles')\n",
    "        for job_elem in job_elems:\n",
    "            titles.append(extract_job_title_indeed(job_elem))\n",
    "        extracted_info.append(titles)                    \n",
    "    \n",
    "    if 'companies' in desired_characs:\n",
    "        companies = []\n",
    "        cols.append('companies')\n",
    "        for job_elem in job_elems:\n",
    "            companies.append(extract_company_indeed(job_elem))\n",
    "        extracted_info.append(companies)\n",
    "    \n",
    "    if 'links' in desired_characs:\n",
    "        links = []\n",
    "        cols.append('links')\n",
    "        for job_elem in job_elems:\n",
    "            links.append(extract_link_indeed(job_elem))\n",
    "        extracted_info.append(links)\n",
    "    \n",
    "    if 'date_listed' in desired_characs:\n",
    "        dates = []\n",
    "        cols.append('date_listed')\n",
    "        for job_elem in job_elems:\n",
    "            dates.append(extract_date_indeed(job_elem))\n",
    "        extracted_info.append(dates)\n",
    "    \n",
    "    jobs_list = {}\n",
    "    \n",
    "    for j in range(len(cols)):\n",
    "        jobs_list[cols[j]] = extracted_info[j]\n",
    "    \n",
    "    num_listings = len(extracted_info[0])\n",
    "    \n",
    "    return jobs_list, num_listings\n",
    "\n",
    "\n",
    "def extract_job_title_indeed(job_elem):\n",
    "    title_elem = job_elem.find('h2', class_='title')\n",
    "    title = title_elem.text.strip()\n",
    "    return title\n",
    "\n",
    "def extract_company_indeed(job_elem):\n",
    "    company_elem = job_elem.find('span', class_='company')\n",
    "    company = company_elem.text.strip()\n",
    "    return company\n",
    "\n",
    "def extract_link_indeed(job_elem):\n",
    "    link = job_elem.find('a')['href']\n",
    "    link = 'www.careersinafrica.com/' + link\n",
    "    return link\n",
    "\n",
    "def extract_date_indeed(job_elem):\n",
    "    date_elem = job_elem.find('span', class_='date')\n",
    "    date = date_elem.text.strip()\n",
    "    return date\n",
    "\n",
    "\n",
    "\n",
    "## ================== FUNCTIONS FOR CWJOBS.CO.UK =================== ##\n",
    "    \n",
    "\n",
    "def initiate_driver(location_of_driver, browser):\n",
    "    if browser == 'chrome':\n",
    "        driver = webdriver.Chrome(executable_path=(location_of_driver + \"/chromedriver\"))\n",
    "    elif browser == 'firefox':\n",
    "        driver = webdriver.Firefox(executable_path=(location_of_driver + \"/firefoxdriver\"))\n",
    "    elif browser == 'safari':\n",
    "        driver = webdriver.Safari(executable_path=(location_of_driver + \"/safaridriver\"))\n",
    "    elif browser == 'edge':\n",
    "        driver = webdriver.Edge(executable_path=(location_of_driver + \"/edgedriver\"))\n",
    "    return driver\n",
    "\n",
    "def make_job_search(job_title, location, driver):\n",
    "    driver.get('https://www.cwjobs.co.uk/')\n",
    "    \n",
    "    # Select the job box\n",
    "    job_title_box = driver.find_element_by_name('Keywords')\n",
    "\n",
    "    # Send job information\n",
    "    job_title_box.send_keys(job_title)\n",
    "\n",
    "    # Selection location box\n",
    "    location_box = driver.find_element_by_id('location')\n",
    "    \n",
    "    # Send location information\n",
    "    location_box.send_keys(location)\n",
    "    \n",
    "    # Find Search button\n",
    "    search_button = driver.find_element_by_id('search-button')\n",
    "    search_button.click()\n",
    "\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    job_soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    return job_soup\n",
    "\n",
    "\n",
    "def extract_job_information_cwjobs(job_soup, desired_characs):\n",
    "    \n",
    "    job_elems = job_soup.find_all('div', class_=\"job\")\n",
    "     \n",
    "    cols = []\n",
    "    extracted_info = []\n",
    "    \n",
    "    if 'titles' in desired_characs:\n",
    "        titles = []\n",
    "        cols.append('titles')\n",
    "        for job_elem in job_elems:\n",
    "            titles.append(extract_job_title_cwjobs(job_elem))\n",
    "        extracted_info.append(titles) \n",
    "                           \n",
    "    \n",
    "    if 'companies' in desired_characs:\n",
    "        companies = []\n",
    "        cols.append('companies')\n",
    "        for job_elem in job_elems:\n",
    "            companies.append(extract_company_cwjobs(job_elem))\n",
    "        extracted_info.append(companies)\n",
    "    \n",
    "    if 'links' in desired_characs:\n",
    "        links = []\n",
    "        cols.append('links')\n",
    "        for job_elem in job_elems:\n",
    "            links.append(extract_link_cwjobs(job_elem))\n",
    "        extracted_info.append(links)\n",
    "                \n",
    "    if 'date_listed' in desired_characs:\n",
    "        dates = []\n",
    "        cols.append('date_listed')\n",
    "        for job_elem in job_elems:\n",
    "            dates.append(extract_date_cwjobs(job_elem))\n",
    "        extracted_info.append(dates)    \n",
    "    \n",
    "    jobs_list = {}\n",
    "    \n",
    "    for j in range(len(cols)):\n",
    "        jobs_list[cols[j]] = extracted_info[j]\n",
    "    \n",
    "    num_listings = len(extracted_info[0])\n",
    "    \n",
    "    return jobs_list, num_listings\n",
    "\n",
    "\n",
    "def extract_job_title_cwjobs(job_elem):\n",
    "    title_elem = job_elem.find('h2')\n",
    "    title = title_elem.text.strip()\n",
    "    return title\n",
    " \n",
    "def extract_company_cwjobs(job_elem):\n",
    "    company_elem = job_elem.find('h3')\n",
    "    company = company_elem.text.strip()\n",
    "    return company\n",
    "\n",
    "def extract_link_cwjobs(job_elem):\n",
    "    link = job_elem.find('a')['href']\n",
    "    return link\n",
    "\n",
    "def extract_date_cwjobs(job_elem):\n",
    "    link_elem = job_elem.find('li', class_='date-posted')\n",
    "    link = link_elem.text.strip()\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
